# 2.4 Probabilidad condicional

Es una medida que nos dice cu치n probable es que ocurra un evento 洧냢 cuando ya sabemos que otro evento 洧냣 ha sucedido

# Ejemplo de Canicas en una Bolsa

Imagina una bolsa con **3 canicas verdes** y **2 canicas rojas** (5 en total). Se extraen **dos canicas una despu칠s de la otra**, y queremos saber la probabilidad de que ambas sean **verdes**.

Antes de sacar ninguna, la probabilidad de obtener verde es:

$$
P(\text{verde}) = \frac{3}{5} = 0.6
$$

Ahora, si sabemos que la primera canica extra칤da fue verde, la bolsa cambia:

- Quedan **2 canicas verdes y 2 canicas rojas**, con **4 canicas en total**.
- La nueva probabilidad de que la segunda tambi칠n sea verde es:

$$
P(\text{verde}_2 \mid \text{ya sali칩 verde}_1) = \frac{2}{4} = 0.5
$$

Multiplicamos ambas probabilidades:

$$
P(\text{verde}_1 \cap \text{verde}_2) = P(\text{verde}_1) \times P(\text{verde}_2 \mid \text{verde}_1)
$$

$$
P(\text{verde}_1 \cap \text{verde}_2) = \frac{3}{5} \times \frac{2}{4} = \frac{6}{20} = 0.3
$$

### **Concepto:**
La probabilidad **se actualiza** porque ahora tenemos **menos opciones totales** y menos verdes disponibles. Al reducir el n칰mero de canicas en la bolsa, la proporci칩n cambia, afectando la probabilidad del siguiente evento. En este caso, hay un **30% de probabilidad** de sacar **dos canicas verdes seguidas**.

### **Definici칩n:**  
Dados dos eventos $A$ y $B$, donde $A, B \subseteq \Omega$, si $P(B) \neq 0$, la **probabilidad condicional** de $A$ dado $B$ se define como:

$$
P(A \mid B) = \frac{P(A \cap B)}{P(B)}
$$

### **Interpretaci칩n Conceptual:**  
La **probabilidad condicional** de $A$ dado $B$ representa **qu칠 tan probable es que ocurra $A$, bajo la condici칩n de que ya sabemos que $B$ ha ocurrido**.  

Es decir, estamos restringiendo nuestro an치lisis al subconjunto de casos en los que $B$ sucede, y dentro de esos casos, evaluamos cu치ntos corresponden a $A$.

## Ley de la probabilidad Total

La **Ley de la Probabilidad Total** nos permite calcular la probabilidad de un evento combinando m칰ltiples casos posibles que lo pueden causar.

**eventos mutuamente excluyentes:** Son aquellos que no pueden ocurrir al mismo tiempo. Si uno sucede, el otro automaticamente no puede ocurrir

$P(A\cap B) = 0$

**Ejemplo pr치ctico:** Imagina que lanzas un dado:

-Evento A: Obtener un n칰mero par; `A: {2, 4, 6}`
-Evento B: Obtener un n칰mero impar; `B: {1, 3, 5}`

Aqu칤, A y B son mutuamente excluyentes, porque no puedes obtener un n칰mero par e impar al mismo tiempo.

### **Definici칩n:**

Si un evento $A$ puede ocurrir bajo diferentes condiciones $B_1$, $B_2$, ..., $B_n$, que forman una **partici칩n** del espacio muestral (es decir, son **eventos mutuamente excluyentes**  y su uni칩n cubre todo el espacio de resultados), entonces la probabilidad de $A$ es:

$P(A)= \sum_{i=1}^n P(A \mid B_i)P(B_i)$

### **Concepto:** 

Imagina que la probabilidad de un evento depende de varios escenarios posibles


# Teorema de Bayes

El **Teorema de Bayes** nos permite actualizar nuestras creencias sobre un evento a medida que obtenemos nueva informaci칩n.

## **Concepto:**

Imagina que tienes una creencia inicial sobre algo (probabilidad previa), pero luego obtienes nueva evidencia que te hace reconsiderarla. El Teorema de Bayes nos dice c칩mo combinar la informaci칩n nueva con lo que ya sab칤amos para calcular una probabilidad actualizada.

Es especialmente 칰til cuando queremos conocer la probabilidad de una causa (洧냣) dado que observamos un efecto (A).

El **Teorema de Bayes** se expresa matem치ticamente como:

$P(B \mid A) = \frac{P(A \mid B)P(B)}{P(B)}$

**Explicci칩n de cada termino**

- $P(B \mid A)$: La probabilidad posterior, es decir, la probabilidad de que el evento 
洧냣 ocurra dado que ya ocurri칩 A.

- $P(A \mid B)$: La verosimilitud, es decir, la probabilidad de observar 
洧냢 si B es cierto.

- $P(B):$ La probabilidad previa (o prior), es la creencia inicial sobre B antes de observar A.

- $P(A):$ La probabilidad total de 洧냢, que puede calcularse usando la Ley de la Probabilidad Total si hay varios posibles eventos que pueden causar 洧냢




